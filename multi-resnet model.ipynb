{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNndzqJjK4L6"
      },
      "source": [
        "### 1 import python packages\n",
        "\n",
        "Using these powerful packages can help us dealing with dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLunqUl0Lc88",
        "outputId": "136f870f-48ef-48dc-dc78-d187e81ea36e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,Sequential,optimizers\n",
        "import random\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "#import torch\n",
        "import math\n",
        "import collections\n",
        "import os\n",
        "import logging\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkH_q2BNK8Ii",
        "outputId": "8996993c-b35c-4925-b47d-a032e4c8c63e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `filename='/content/log/{:%Y-%m-%d}.log'.format'\n",
            "/bin/bash: -c: line 1: `logging.basicConfig(filename='/content/log/{:%Y-%m-%d}.log'.format(datetime.now()))'\n"
          ]
        }
      ],
      "source": [
        "!logging.basicConfig(filename='/content/log/{:%Y-%m-%d}.log'.format(datetime.now()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HWoN6V-gp56u"
      },
      "outputs": [],
      "source": [
        "model_weights_file = '..//content//model//resnet_model.ckpt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "r0HfMgjep_P-"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/training_labels.csv')\n",
        "test_df = pd.read_csv('/content/sample_submission.csv')\n",
        "def get_file_path(idx, train = True):\n",
        "    path = \"../content/g2net-image/\"\n",
        "    if train:\n",
        "        path += 'train/'\n",
        "    else:\n",
        "        path += 'test/'\n",
        "\n",
        "    path += idx+'.npy'\n",
        "    return path\n",
        "\n",
        "train_df['path'] = train_df['id'].apply(get_file_path, train = True)\n",
        "test_df['path'] = test_df['id'].apply(get_file_path, train = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RWtZ4iYi9Wqg"
      },
      "outputs": [],
      "source": [
        "num_classes = 1 # the number of distinct classes is trained to classify.\n",
        "batch_size = 500 # batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_n48xUXN9aZh"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_from_label(path, label):\n",
        "    path = path.numpy()\n",
        "    image = np.load(path.decode()).astype(np.float32)\n",
        "    image = (image - 0.75) * 4\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.convert_to_tensor(image, tf.float32)\n",
        "    image = tf.squeeze(image)\n",
        "    label = tf.expand_dims(label, -1)\n",
        "    label = tf.cast(label, tf.int32)\n",
        "    label = tf.convert_to_tensor(label, tf.int32)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "def preprocess_test(path, labelid):\n",
        "    path = path.numpy()\n",
        "    image = np.load(path.decode()).astype(np.float32)\n",
        "    image = (image - 0.75) * 4\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.convert_to_tensor(image, tf.float32)\n",
        "    image = tf.squeeze(image)\n",
        "    labelid = tf.convert_to_tensor(labelid, tf.string)\n",
        "    return image, labelid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "v8dsuGzE9ioU"
      },
      "outputs": [],
      "source": [
        "\n",
        "allPath,allPathTest = tf.convert_to_tensor(train_df['path'], dtype=tf.string), \\\n",
        "    tf.convert_to_tensor(test_df['path'], dtype=tf.string)\n",
        "train_target,test_target = tf.convert_to_tensor(train_df['target'].to_numpy(), dtype=tf.int32), \\\n",
        "    tf.convert_to_tensor(test_df['id'].to_numpy(), dtype=tf.string)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((allPath, train_target))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((allPathTest, test_target))\n",
        "\n",
        "train_dataset = train_dataset.map(lambda x,y: tf.py_function(load_and_preprocess_from_label,[x, y],[tf.float32, tf.int32]))\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.map(lambda x,y: tf.py_function(preprocess_test,[x, y],[tf.float32, tf.string]))\n",
        "test_dataset = test_dataset.batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH91DQae90dE",
        "outputId": "1ddbee81-6036-45f5-e217-9b29c169a4d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0 -0.9999652 (500, 64, 129, 3) (500, 1)\n"
          ]
        }
      ],
      "source": [
        "for x, y in train_dataset.take(1):\n",
        "    print(np.max(x),np.min(x), x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOJ9kwDM91et"
      },
      "source": [
        "### 2 Building model for multi-ResNet model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CoZbPx4499IB"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(layers.Layer):\n",
        "\n",
        "    def __init__(self, filter_num, strides=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = layers.Conv2D(filter_num, kernel_size=3, strides=strides, padding='same', bias=False)\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.relu = layers.Activation('relu')\n",
        "\n",
        "        self.conv2 = layers.Conv2D(filter_num, kernel_size=3, strides=1, padding='same', bias=False)\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "\n",
        "        if strides != 1:\n",
        "            self.downsample = Sequential()\n",
        "            self.downsample.add(layers.Conv2D(filter_num, kernel_size=1, strides=strides, bias=False))\n",
        "        else:\n",
        "            self.downsample = lambda x:x\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "\n",
        "        out = self.conv1(inputs)\n",
        "        out = self.bn1(out, training=training)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out, training=training)\n",
        "\n",
        "        identity = self.downsample(inputs)\n",
        "\n",
        "        output = layers.add([out, identity])\n",
        "        output = tf.nn.relu(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "class Bottleneck(layers.Layer):\n",
        "    expansion = 4\n",
        "    def __init__(self, filter_num, strides=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "\n",
        "        self.conv1 = layers.Conv2D(filter_num, kernel_size=1, use_bias=False)\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.relu = layers.Activation('relu')\n",
        "\n",
        "        self.conv2 = layers.Conv2D(filter_num, kernel_size=3, strides=strides, use_bias=False, padding='same')\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "        self.relu = layers.Activation('relu')\n",
        "\n",
        "        self.conv3 = layers.Conv2D(filter_num * self.expansion, kernel_size=1, strides=1, use_bias=False, padding='same')\n",
        "        self.bn3 = layers.BatchNormalization()\n",
        "\n",
        "        if strides != 1 or filter_num != filter_num * self.expansion:\n",
        "            self.downsample = Sequential()\n",
        "            self.downsample.add(layers.Conv2D(filter_num * self.expansion, kernel_size=1, strides=strides, use_bias=False))\n",
        "        else:\n",
        "            self.downsample = lambda x:x\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        out = self.conv1(inputs)\n",
        "        out = self.bn1(out, training=training)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out, training=training)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out, training=training)\n",
        "\n",
        "        identity = self.downsample(inputs)\n",
        "\n",
        "        output = layers.add([out, identity])\n",
        "        output = tf.nn.relu(output)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NSILn235-YXs"
      },
      "outputs": [],
      "source": [
        "class ResNet(keras.Model):\n",
        "\n",
        "    def __init__(self, layer_dims, num_classed=10, is_neck=False): #[2,2,2,2]\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.stem = Sequential([layers.Conv2D(filters=64, kernel_size=7, strides=2, use_bias=False),\n",
        "                               layers.BatchNormalization(),\n",
        "                               layers.Activation('relu'),\n",
        "                               layers.MaxPool2D(pool_size=3, strides=2, padding='same')])\n",
        "\n",
        "        if is_neck:\n",
        "            self.layer1 = self.build_resblockneck(64, layer_dims[0])\n",
        "            self.layer2 = self.build_resblockneck(128, layer_dims[1], strides=2)\n",
        "            self.layer3 = self.build_resblockneck(256, layer_dims[2], strides=2)\n",
        "            self.layer4 = self.build_resblockneck(512, layer_dims[3], strides=2)\n",
        "        else:\n",
        "            self.layer1 = self.build_resblock(64, layer_dims[0])\n",
        "            self.layer2 = self.build_resblock(128, layer_dims[1], strides=2)\n",
        "            self.layer3 = self.build_resblock(256, layer_dims[2], strides=2)\n",
        "            self.layer4 = self.build_resblock(512, layer_dims[3], strides=2)\n",
        "\n",
        "        self.avgpool = layers.GlobalAveragePooling2D()\n",
        "        self.fc = layers.Dense(num_classes, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        x = self.stem(inputs, training=training)\n",
        "        x = self.layer1(x, training=training)\n",
        "        x = self.layer2(x, training=training)\n",
        "        x = self.layer3(x, training=training)\n",
        "        x = self.layer4(x, training=training)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def build_resblock(self, filter_num, blocks, strides=1):\n",
        "\n",
        "        res_blocks = Sequential()\n",
        "        res_blocks.add(BasicBlock(filter_num, strides))\n",
        "\n",
        "        for _ in range(1, blocks):\n",
        "            res_blocks.add(BasicBlock(filter_num, strides=1))\n",
        "\n",
        "        return res_blocks\n",
        "\n",
        "    def build_resblockneck(self, filter_num, blocks, strides=1):\n",
        "\n",
        "        res_blocks = Sequential()\n",
        "        res_blocks.add(Bottleneck(filter_num, strides))\n",
        "\n",
        "        for _ in range(1, blocks):\n",
        "            res_blocks.add(Bottleneck(filter_num, strides=1))\n",
        "\n",
        "        return res_blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3 You can choose what you want model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ig8gdKzA-6JB"
      },
      "outputs": [],
      "source": [
        "def resnet16():\n",
        "    return ResNet([1, 2, 2, 1],is_neck=True)\n",
        "\n",
        "def resnet18():\n",
        "    return ResNet([2, 2, 2, 2],is_neck=True)\n",
        "\n",
        "def resnet34():\n",
        "    return ResNet([3, 4, 6, 3])\n",
        "\n",
        "def resnet50():\n",
        "    return ResNet([3, 4, 6, 3], is_neck=True)\n",
        "\n",
        "def resnet101():\n",
        "    return ResNet([3, 4, 23, 3], is_neck=True)\n",
        "\n",
        "def resnet152():\n",
        "    return ResNet([3, 8, 36, 3], is_neck=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zsafvuwz--3x",
        "outputId": "0905e70a-267e-4b18-b34f-b1fc4fb7c073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"res_net\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 16, 31, 64)        9664      \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 16, 31, 256)       75264     \n",
            "                                                                 \n",
            " sequential_3 (Sequential)   (None, 8, 16, 512)        923648    \n",
            "                                                                 \n",
            " sequential_6 (Sequential)   (None, 4, 8, 1024)        3682304   \n",
            "                                                                 \n",
            " sequential_9 (Sequential)   (None, 2, 4, 2048)        6041600   \n",
            "                                                                 \n",
            " global_average_pooling2d (G  multiple                 0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,734,529\n",
            "Trainable params: 10,718,273\n",
            "Non-trainable params: 16,256\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "resnet = resnet16()\n",
        "resnet.build(input_shape=(None, 69, 129, 3))\n",
        "resnet.summary()\n",
        "if os.path.exists(model_weights_file + '.index'):\n",
        "    resnet.load_weights(model_weights_file)\n",
        "    print('load weights.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "JtQOK-PN-_fu"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff1Gray6_BFS",
        "outputId": "7887bf5d-d4a6-464b-f03b-fb2874c7351c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "00:00:01\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "def format_seconds(sec):\n",
        "    m, s = divmod(sec, 60)\n",
        "    h, m = divmod(m, 60)\n",
        "    return (\"%02d:%02d:%02d\" % (h, m, s))\n",
        "\n",
        "start = time.perf_counter()\n",
        "time.sleep(1)\n",
        "dur = time.perf_counter()\n",
        "dif = dur - start\n",
        "print(format_seconds(dif))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4 build training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "hDlYAiqi_ClL"
      },
      "outputs": [],
      "source": [
        "\n",
        "def computeAcc(label, pred):\n",
        "    pred = pred // 0.5\n",
        "    correct = tf.reduce_sum(tf.cast(tf.equal(tf.cast(pred, tf.int32), tf.cast(label, tf.int32)),tf.int32))\n",
        "    return correct\n",
        "\n",
        "def train(epoch, logStep = 1, saveStep = 1000):\n",
        "    total_num, total_loss, total_correct = 0, 0, 0\n",
        "    cur_num, cur_loss, cur_correct  = 0, 0, 0\n",
        "    cnt = train_df.count()[0] // batch_size\n",
        "    scale = cnt // 30\n",
        "    start = time.perf_counter()\n",
        "    for step,(x,y) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = resnet(x,training=True)\n",
        "            #loss\n",
        "            loss = tf.losses.binary_crossentropy(y, logits)\n",
        "            loss = tf.reduce_mean(loss)\n",
        "\n",
        "        #print(loss.trainable_variables)\n",
        "        grads = tape.gradient(loss, resnet.trainable_variables)\n",
        "        #print(grads)\n",
        "        optimizer.apply_gradients(zip(grads, resnet.trainable_variables))\n",
        "\n",
        "        correct = computeAcc(y, logits)\n",
        "\n",
        "#         cur_num += x.shape[0]\n",
        "#         cur_loss += loss * x.shape[0]\n",
        "#         cur_correct += int(correct)\n",
        "        total_num += x.shape[0]\n",
        "        total_correct += int(correct)\n",
        "        total_loss += loss\n",
        "\n",
        "#         if step % logStep == 0:\n",
        "#             acc = cur_correct / cur_num\n",
        "#             #logging.getLogger().info(epoch, step,'/',total_num, ' loss:', float(cur_loss / cur_num),'acc=', acc)\n",
        "#             cur_correct = 0\n",
        "#             cur_num = 0\n",
        "#             cur_loss = 0\n",
        "\n",
        "        if step % saveStep == 0 and step != 0:\n",
        "            resnet.save_weights(model_weights_file)\n",
        "            print('saved weights.')\n",
        "\n",
        "        a = \"*\" * (step // scale)\n",
        "        b = \".\" * ((cnt - step) // scale)\n",
        "        c = (step / cnt) * 100\n",
        "        dur = (time.perf_counter() - start)\n",
        "        start = time.perf_counter()\n",
        "        print(\"\\r epoch({:^d}) now used time ls:{:^.5f} acc:{:^.3f} total loss:{:^.5f} Acc:{:^.3f} {:^3.2f}% [{}->{}]{:^.2f}s need time:{} {:^d}   \"\\\n",
        "              .format(epoch, loss, correct / batch_size, total_loss / (step + 1), total_correct / total_num, c,a,b,dur \\\n",
        "              ,format_seconds(dur * (cnt - step)), total_num),end = \"\")\n",
        "\n",
        "    #acc = total_correct / total_num\n",
        "    #print(epoch, 'acc=', acc,'total_num=', total_num)\n",
        "\n",
        "    resnet.save_weights(model_weights_file)\n",
        "    print('saved weights.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Mgh3kL2RIeSj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def test(epoch):\n",
        "    y_pred = []\n",
        "    ids = []\n",
        "    test_num = 0\n",
        "    start = time.perf_counter()\n",
        "    proCnt = 20\n",
        "    for step,(x,y) in enumerate(test_dataset):\n",
        "\n",
        "        #print(step)\n",
        "        out = resnet(x, training=False)\n",
        "        test_num += x.shape[0]\n",
        "\n",
        "        y_pred.extend(tf.squeeze(out).numpy())\n",
        "        ids.extend(y.numpy().astype(str))\n",
        "\n",
        "        cnt = test_df.count()[0] // batch_size\n",
        "        scale = cnt // proCnt\n",
        "        a = \"*\" * (step // scale)\n",
        "        b = \".\" * ((cnt - step) // scale)\n",
        "        c = (step / cnt) * 100\n",
        "        dur = (time.perf_counter() - start)\n",
        "        start = time.perf_counter()\n",
        "        print(\"\\r{:^3.1f}%[{}->{}]{:^.2f}s need time:\".format(c,a,b,dur) + format_seconds(dur * (cnt - step)),end = \"\")\n",
        "\n",
        "    submission = pd.DataFrame({\"id\": ids, \"target\": y_pred})\n",
        "    print(submission)\n",
        "    submission.to_csv(\"submission(\"+ str(epoch)+\").csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XvVOo4xIh2K",
        "outputId": "4db5e734-f4b7-4722-fbb7-3804882a88f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " epoch(0) now used time ls:1.58439 acc:0.478 total loss:2.39270 Acc:0.480 0.09% [->..............................]72.37s need time:22:29:42 1000   "
          ]
        }
      ],
      "source": [
        "for epoch in range(15):\n",
        "    train_dataset = train_dataset.shuffle(buffer_size=1)\n",
        "    train(epoch, 1, 3000)\n",
        "    test(epoch)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
